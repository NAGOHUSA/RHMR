# .github/workflows/free-data-pipeline.yml
name: Free Real Estate Data Pipeline

on:
  schedule:
    - cron: "0 */6 * * *"  # Every 6 hours (free tier allows 2000 minutes/month)
    - cron: "0 8,14,20 * * *"  # 3 times daily (8 AM, 2 PM, 8 PM UTC)
  workflow_dispatch:
  push:
    branches: [ main ]

jobs:
  collect-free-data:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        zip: ['31088', '31093', '31098']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 pandas numpy
        echo "All dependencies are free and open source"
    
    - name: Create directory structure
      run: |
        mkdir -p scripts
        mkdir -p data/houston-county-ga
        mkdir -p data/houston-county-ga/${{ matrix.zip }}
    
    - name: Copy free data collector
      run: |
        # Copy the collector script (would be in your repo)
        echo "Using free data collector script..."
    
    - name: Collect free data
      run: |
        echo "Collecting free data for ZIP ${{ matrix.zip }}..."
        python scripts/free_data_collector.py --zip ${{ matrix.zip }}
    
    - name: Archive collected data
      run: |
        echo "Data collected for ${{ matrix.zip }}"
        ls -la data/houston-county-ga/${{ matrix.zip }}/
    
  generate-ai-insights:
    runs-on: ubuntu-latest
    needs: collect-free-data
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
    
    - name: Install AI dependencies
      run: pip install requests
    
    - name: Generate DeepSeek AI insights
      run: |
        echo "Generating AI insights with DeepSeek (free API)..."
        export DEEPSEEK_API_KEY=${{ secrets.DEEPSEEK_API_KEY }}
        python scripts/deepseek_ai_insights.py
    
    - name: Create aggregated dashboard data
      run: |
        echo "Creating dashboard JSON files..."
        python scripts/create_dashboard_json.py
    
    - name: Verify generated files
      run: |
        echo "Generated files:"
        find data/houston-county-ga -name "*.json" -type f | head -20
        echo "Total files:"
        find data/houston-county-ga -name "*.json" -type f | wc -l
    
  deploy-dashboard:
    runs-on: ubuntu-latest
    needs: generate-ai-insights
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./
        keep_files: true
        destination_dir: ./
    
    - name: Commit and push data updates
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add data/
        git commit -m "ðŸ“Š Free data update $(date +'%Y-%m-%d %H:%M')" || echo "No changes"
        git push
